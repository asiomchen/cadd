{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader,random_split, Dataset\n",
    "from utils.fixes import global_seed\n",
    "import warnings\n",
    "global_seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "smifile = \"GDB17.50000000LLnoSR.smi\"\n",
    "data = pd.read_csv(smifile, delimiter = \"\\t\", names = [\"smiles\"])\n",
    "data = data.sample(n=100000).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'CC1C2NC(=O)C(C)C(N)=NC2(C)CC1(C)C'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.smiles[5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# max len smiles\n",
    "MAX_SMILES_LEN = max([len(smile) for smile in data.smiles]) + 5\n",
    "print(MAX_SMILES_LEN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "multi_char = [\"Cl\", \"Br\", \"Si\"]\n",
    "single_char = ['#', ')', '(', '+', '-', '/', '1', '3', '2', '5', '4', '7', '6', '8', '=', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'S', '[', ']', '\\\\', 'c', 'l', 'o', 'n', 'p', 's', 'r']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import re"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# create tokenizer for smiles strings\n",
    "class SMILESTokenizer:\n",
    "    def __init__(self, multi_char=[\"Cl\", \"Br\", \"Si\"], start='?', end='E', max_len=60):\n",
    "        self.multi_char = multi_char\n",
    "        self.single_char = ['#', ')', '(', '+', '-', '/', '1', '3', '2', '5', '4', '7', '6', '8', '=', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'S', '[', ']', '\\\\', 'c', 'l', 'o', 'n', 'p', 's', 'r']\n",
    "        self.multi_pattern = self._generate_regex(multi_char)\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.max_len = max_len\n",
    "        self.vocab = self.single_char + self.multi_char\n",
    "        self_pad = '<pad>'\n",
    "        self.char2idx = {start: 1, end: 2, self_pad: 0}\n",
    "        self.char2idx.update({char: idx + 3 for idx, char in enumerate(self.vocab)})\n",
    "        self.idx2char = {idx: char for char, idx in self.char2idx.items()}\n",
    "        self.vocab.extend([start])\n",
    "    def tokenize(self, smiles):\n",
    "        if len(smiles) > self.max_len:\n",
    "            warnings.warn(f\"SMILES string is longer than {self.max_len -1} characters. Skipping...\")\n",
    "            return None\n",
    "        smiles = self.start + smiles + self.end\n",
    "        split = re.split(self.multi_pattern, smiles)\n",
    "        out = []\n",
    "        for x in split:\n",
    "            if x in self.multi_char:\n",
    "                out.append(x)\n",
    "                continue\n",
    "            if x is None:\n",
    "                continue\n",
    "            for y in x:\n",
    "                out.append(y)\n",
    "        without_pad = [self.char2idx[x] for x in out]\n",
    "        return without_pad + [0] * (self.max_len - len(without_pad))\n",
    "    def detokenize(self, tokens, remove_start_end=True, remove_padding=True):\n",
    "        if isinstance(tokens, torch.Tensor):\n",
    "            tokens = tokens.tolist()\n",
    "        raw_string = \"\".join([self.idx2char[x] for x in tokens])\n",
    "        if remove_padding:\n",
    "            raw_string = raw_string.replace(\"<pad>\", \"\")\n",
    "        if remove_start_end:\n",
    "            raw_string = raw_string.replace(self.start, \"\").replace(self.end, \"\")\n",
    "        return raw_string\n",
    "\n",
    "    def _generate_regex(self, multi_char):\n",
    "        grouped = [f\"({x})\" for x in multi_char]\n",
    "        multi_pattern = \"|\".join(grouped)\n",
    "        return multi_pattern\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tokenizer = SMILESTokenizer(max_len=50)\n",
    "encoded = tokenizer.tokenize('CCCNBr')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 19, 19, 19, 25, 38, 2]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'CCCNBr'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(encoded)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 19, 19, 25, 2]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.smiles[6000] == tokenizer.detokenize(tokenizer.tokenize(data.smiles[6000]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1, 19, 19, 19, 25, 38,  2],\n        [ 1, 19, 19, 25,  2,  0,  0]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=50):\n",
    "        self.smiles = data.smiles.to_list()\n",
    "        self.tokenizer = tokenizer(max_len=max_len)\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "    def __getitem__(self, idx):\n",
    "        smiles_raw = self.smiles[idx]\n",
    "        encoded = self.tokenizer.tokenize(smiles_raw)\n",
    "        return torch.tensor(encoded, dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "PackedSequence(data=tensor([ 1,  1, 19, 19, 19, 19, 19, 25, 25,  2, 38,  2]), batch_sizes=tensor([2, 2, 2, 2, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = SMILESDataset(data, SMILESTokenizer, max_len=MAX_SMILES_LEN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<function torchtext.datasets.multi30k.Multi30k(root: str = '.data', split: Union[Tuple[str], str] = ('train', 'valid', 'test'), language_pair: Tuple[str] = ('de', 'en'))>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SMILESTokenizer(max_len=MAX_SMILES_LEN)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 1, 19, 19, 19,  5, 19,  3, 19,  4, 19,  5, 19,  4, 19, 19,  9, 17, 25,\n        25, 19,  5, 25, 19, 19, 17, 24,  4, 17, 25,  9,  2,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[7]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(dataset[7]) == data.smiles[7]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 2D tensor: torch.Size([2, 3])\n",
      "Shape after view: torch.Size([1, 1, 6])\n",
      "tensor([[[1, 2, 3, 4, 5, 6]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "example_2D_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f'Shape of 2D tensor: {example_2D_tensor.shape}')\n",
    "print(f'Shape after view: {example_2D_tensor.view(1, 1, -1).shape}')\n",
    "print(example_2D_tensor.view(1, 1, -1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.encoder = nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
    "        self.hidden_size = hidden_size\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.encoder(x)\n",
    "        return hidden[-1]\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.decoder = nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.activation = nn.LogSoftmax(dim=2)\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.start = torch.tensor([1])\n",
    "    def forward(self, hidden):\n",
    "        x = self.start.repeat(self.batch_size, 1)\n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.decoder(x, hidden)\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x, hidden\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = Encoder(vocab_size=32, embedding_size=32, hidden_size=16)\n",
    "dummy_input = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]])\n",
    "h = encoder(dummy_input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 16])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7786,  0.0748, -0.5652,  0.5272,  0.8104,  0.0347, -0.2540,  0.0094,\n          0.3040,  0.1887, -0.0108,  0.2584,  0.3977,  0.1729,  0.7098, -0.0173]],\n       grad_fn=<SelectBackward0>)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_batch = dummy_input.repeat(5, 1)\n",
    "dummy_batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7786,  0.0748, -0.5652,  0.5272,  0.8104,  0.0347, -0.2540,  0.0094,\n          0.3040,  0.1887, -0.0108,  0.2584,  0.3977,  0.1729,  0.7098, -0.0173],\n        [-0.7786,  0.0748, -0.5652,  0.5272,  0.8104,  0.0347, -0.2540,  0.0094,\n          0.3040,  0.1887, -0.0108,  0.2584,  0.3977,  0.1729,  0.7098, -0.0173],\n        [-0.7786,  0.0748, -0.5652,  0.5272,  0.8104,  0.0347, -0.2540,  0.0094,\n          0.3040,  0.1887, -0.0108,  0.2584,  0.3977,  0.1729,  0.7098, -0.0173],\n        [-0.7786,  0.0748, -0.5652,  0.5272,  0.8104,  0.0347, -0.2540,  0.0094,\n          0.3040,  0.1887, -0.0108,  0.2584,  0.3977,  0.1729,  0.7098, -0.0173],\n        [-0.7786,  0.0748, -0.5652,  0.5272,  0.8104,  0.0347, -0.2540,  0.0094,\n          0.3040,  0.1887, -0.0108,  0.2584,  0.3977,  0.1729,  0.7098, -0.0173]],\n       grad_fn=<SelectBackward0>)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(dummy_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
